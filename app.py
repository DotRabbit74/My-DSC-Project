import streamlit as st
import torch
import torchvision.transforms as T
from PIL import Image
import time
import os
import sys

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="Deep Scene Curve Demo",
    page_icon="ğŸŒŠ",
    layout="wide"
)

# --- 2. æª¢æŸ¥ä¸¦åŒ¯å…¥æ¨¡å‹ ---
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

try:
    from model_dsc import Network
except ImportError:
    st.error("âŒ æ‰¾ä¸åˆ° `model_dsc.py`ã€‚è«‹ç¢ºä¿æ­¤æª”æ¡ˆå·²ä¸Šå‚³è‡³ GitHub å„²å­˜åº«çš„æ ¹ç›®éŒ„ã€‚")
    st.stop()

# --- 3. è¨­å®šåŸ·è¡Œè£ç½® ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

@st.cache_resource
def load_model(weights_path, mode):
    """ è¼‰å…¥æ¨¡å‹æ¬Šé‡ """
    if not os.path.exists(weights_path):
        return None

    try:
        model = Network(mode=mode)
    except TypeError:
        st.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—ï¼šNetwork é¡åˆ¥ä¼¼ä¹ä¸æ”¯æ´ mode='{mode}' åƒæ•¸ã€‚")
        return None

    try:
        checkpoint = torch.load(weights_path, map_location=device)
        if 'state_dict' in checkpoint:
            model.load_state_dict(checkpoint['state_dict'])
        else:
            model.load_state_dict(checkpoint)
    except Exception as e:
        st.error(f"âš ï¸ æ¬Šé‡æª”ææ¯€æˆ–ä¸ç›¸å®¹ ({weights_path}): {e}")
        return None

    model.to(device)
    model.eval()
    return model

def process_image(model, image):
    """ 
    å½±åƒæ¨è«–èˆ‡è¨ˆæ™‚ 
    """
    w, h = image.size
    
    # å®‰å…¨æ©Ÿåˆ¶ï¼šé™åˆ¶æœ€å¤§é‚Šé•· (é˜²æ­¢ OOM)
    max_size = 1280
    if max(w, h) > max_size:
        scale_factor = max_size / max(w, h)
        new_w = int(w * scale_factor)
        new_h = int(h * scale_factor)
        image = image.resize((new_w, new_h), Image.Resampling.LANCZOS)
    
    transform = T.Compose([T.ToTensor()])
    img_tensor = transform(image).unsqueeze(0).to(device)
    
    start_time = time.time()
    try:
        with torch.no_grad():
            output = model(img_tensor)
            if isinstance(output, (tuple, list)):
                output = output[0]
    except RuntimeError as e:
        if "out of memory" in str(e):
            return image, 0.0 
        raise e
            
    end_time = time.time()
    
    output = torch.clamp(output, 0, 1).squeeze(0).cpu()
    output_img = T.ToPILImage()(output)
    
    return output_img, end_time - start_time

# --- 4. å´é‚Šæ¬„è¨­å®š ---
st.sidebar.title("ğŸŒŠ è¨­å®šé¢æ¿")
st.sidebar.caption(f"Device: `{device}`")
st.sidebar.info("èªªæ˜ï¼šæ­¤æ‡‰ç”¨ç¨‹å¼æ¯”è¼ƒåŸå§‹ Sigmoid æ–¹æ³•èˆ‡æ”¹è‰¯ç‰ˆ Softsign æ–¹æ³•åœ¨æ°´ä¸‹å½±åƒå¢å¼·çš„è¡¨ç¾ã€‚")

PATH_ORIGINAL = "weights/original.pth"
PATH_SOFTSIGN = "weights/softsign.pth"

model_orig = load_model(PATH_ORIGINAL, mode='original')
model_soft = load_model(PATH_SOFTSIGN, mode='softsign')

# --- 5. ä¸»ç•«é¢é‚è¼¯ ---
st.title("ğŸŒŠ Deep Scene Curve (DSC) - Model Comparison")
st.markdown("""
æœ¬å°ˆæ¡ˆå¾©åˆ»ä¸¦æ”¹è‰¯äº† **Deep Scene Curve** æ°´ä¸‹å½±åƒå¢å¼·æ¨¡å‹ã€‚
ä½¿ç”¨ **Softsign** æ›²ç·šä¼°è¨ˆæ–¹æ³•ï¼Œä»¥æå‡æ¨è«–é€Ÿåº¦ä¸¦æ”¹å–„æ¢¯åº¦å‚³éã€‚
""")

# --- [é—œéµä¿®æ”¹] åœ–ç‰‡ä¾†æºé¸æ“‡é‚è¼¯ ---
image = None
uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šå‚³åœ–ç‰‡ (æˆ–ä½¿ç”¨ä¸‹æ–¹ç¯„ä¾‹)", type=["jpg", "png", "jpeg"])

if uploaded_file:
    # å„ªå…ˆä½¿ç”¨ä¸Šå‚³çš„åœ–ç‰‡
    image = Image.open(uploaded_file).convert('RGB')
else:
    # è‹¥ç„¡ä¸Šå‚³ï¼Œæª¢æŸ¥ sample è³‡æ–™å¤¾ (æ³¨æ„é€™è£¡æ”¹æˆäº† "sample")
    current_dir = os.path.dirname(os.path.abspath(__file__))
    sample_dir = os.path.join(current_dir, "sample")
    
    if os.path.exists(sample_dir):
        sample_files = [f for f in os.listdir(sample_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if sample_files:
            # åŠ å…¥ä¸€å€‹ã€Œä½”ä½é¸é …ã€åœ¨æœ€å‰é¢
            placeholder_text = "--- è«‹é¸æ“‡ç¯„ä¾‹åœ–ç‰‡ ---"
            options = [placeholder_text] + sample_files
            
            selected_option = st.selectbox(
                "ğŸ–¼ï¸ æ²’æœ‰åœ–ç‰‡å—ï¼Ÿé¸æ“‡ä¸€å¼µç¯„ä¾‹åœ–ç‰‡ä¾†æ¸¬è©¦ï¼š",
                options,
                index=0  # é è¨­é¸åˆ° "--- è«‹é¸æ“‡ç¯„ä¾‹åœ–ç‰‡ ---"
            )
            
            # åªæœ‰ç•¶ä½¿ç”¨è€…é¸çš„ä¸æ˜¯ä½”ä½æ–‡å­—æ™‚ï¼Œæ‰è¼‰å…¥åœ–ç‰‡
            if selected_option != placeholder_text:
                image_path = os.path.join(sample_dir, selected_option)
                image = Image.open(image_path).convert('RGB')
    
# --- 6. å±•ç¤ºèˆ‡æ¨è«– ---
if image:
    # é€™è£¡çš„é‚è¼¯åªæœ‰åœ¨ image è¢«è¼‰å…¥å¾Œæ‰æœƒåŸ·è¡Œ
    tab1, tab2 = st.tabs(["ğŸ” å–®ä¸€æ¨¡å‹åˆ†æ", "âš¡ A/B æ•ˆèƒ½å°æ±º"])

    with tab1:
        st.subheader("å–®ä¸€æ¨¡å‹è©³ç´°æ¸¬è©¦")
        option = st.radio("é¸æ“‡æ¨¡å‹ç‰ˆæœ¬", ["Original (Sigmoid)", "Modified (Softsign)"], horizontal=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.image(image, caption="åŸå§‹è¼¸å…¥", use_container_width=True)
            
        with col2:
            target_model = model_orig if option == "Original (Sigmoid)" else model_soft
            
            if target_model:
                with st.spinner("æ­£åœ¨å¢å¼·ä¸­..."):
                    res, t = process_image(target_model, image)
                
                st.image(res, caption=f"å¢å¼·çµæœ ({option})", use_container_width=True)
                st.success(f"â±ï¸ æ¨è«–æ™‚é–“: {t*1000:.2f} ms")
                
                if option == "Original (Sigmoid)":
                    st.latex(r"\mathcal{F}(x) = \frac{1}{1+e^{-(\alpha x + \beta)}}")
                else:
                    st.latex(r"\mathcal{F}(x) = 0.5 \times \left( \frac{\alpha x + \beta}{1 + |\alpha x + \beta|} + 1 \right)")
            else:
                st.warning(f"âš ï¸ æ‰¾ä¸åˆ°æ¬Šé‡æª”ï¼Œè«‹ç¢ºèª GitHub ä¸Šæ˜¯å¦æœ‰ `{PATH_ORIGINAL}` æˆ– `{PATH_SOFTSIGN}`ã€‚")

    with tab2:
        st.subheader("âš¡ æ•ˆèƒ½èˆ‡ç•«è³ªä¸¦åˆ—æ¯”è¼ƒ")
        
        c1, c2, c3 = st.columns(3)
        with c1:
            st.markdown("**Original Input**")
            st.image(image, use_container_width=True)
            
        t_o, t_s = 0, 0
        
        with c2:
            st.markdown("**Original (Sigmoid)**")
            if model_orig:
                res_o, t_o = process_image(model_orig, image)
                st.image(res_o, use_container_width=True)
                st.info(f"{t_o*1000:.2f} ms")
            else:
                st.error("Missing Weights")
                
        with c3:
            st.markdown("**Modified (Softsign)**")
            if model_soft:
                res_s, t_s = process_image(model_soft, image)
                st.image(res_s, use_container_width=True)
                st.info(f"{t_s*1000:.2f} ms")
            else:
                st.error("Missing Weights")
        
        if t_o > 0 and t_s > 0:
            st.markdown("---")
            speedup = (t_o - t_s) / t_o * 100
            if speedup > 0:
                st.metric(label="Softsign åŠ é€Ÿå¹…åº¦", value=f"{speedup:.2f}%", delta="Faster")
            else:
                st.metric(label="é€Ÿåº¦å·®ç•°", value=f"{abs(speedup):.2f}%")

else:
    # é è¨­ç•«é¢ï¼šæç¤ºä½¿ç”¨è€…å‹•ä½œ
    st.info("ğŸ‘‹ è«‹ä¸Šå‚³åœ–ç‰‡ï¼Œæˆ–å¾ä¸Šæ–¹é¸å–®é¸æ“‡ä¸€å¼µç¯„ä¾‹åœ–ç‰‡ä»¥é–‹å§‹æ¸¬è©¦ï¼")
